译者序 序 前言 审校者简介 第1章　品味机器学习 1 1.1　初步了解机器学习 1 1.2　机器学习可以解决的事情 3 1.3　初步了解 Python 4 1.4　初步了解 OpenCV 4 1.5　安装 5 1.5.1　获取本书最新的代码 5 1.5.2　掌握 Python Anaconda 6 1.5.3　在 conda 环境中安装OpenCV 8 1.5.4　验证安装结果 9 译者序序前言审校者简介第1章　品味机器学习 11.1　初步了解机器学习 11.2　机器学习可以解决的事情 31.3　初步了解 Python 41.4　初步了解 OpenCV 41.5　安装 51.5.1　获取本书最新的代码 51.5.2　掌握 Python Anaconda 61.5.3　在 conda 环境中安装OpenCV 81.5.4　验证安装结果 91.5.5　一睹 OpenCV ML 模块 111.6　总结 11第2章　使用 OpenCV 和 Python处理数据 122.1　理解机器学习流程 122.2　使用 OpenCV 和 Python 处理数据 142.2.1　创建一个新的 IPython 或 Jupyter 会话 152.2.2　使用 Python 的 NumPy包处理数据 162.2.3　在 Python 中载入外部数据集 202.2.4　使用 Matplotlib 进行数据可视化 212.2.5　使用C   中 OpenCV 的 TrainData 容器处理数据 262.3　总结 27第3章　监督学习的第一步 283.1　理解监督学习 283.1.1　了解 OpenCV 中的监督学习 293.1.2　使用评分函数评估模型性能 303.2　使用分类模型预测类别 353.2.1　理解 k-NN 算法 373.2.2　使用 OpenCV实现 k-NN 373.3　使用回归模型预测连续结果 433.3.1　理解线性回归 433.3.2　使用线性回归预测波士顿房价 443.3.3　应用 Lasso 回归和ridge 回归 483.4　使用逻辑回归对鸢尾花种类进行分类 483.5　总结 53第4　数据表示与特征工程 544.1　理解特征工程 544.2　数据预处理 554.2.1　特征标准化 564.2.2　特征归一化 574.2.3　特征缩放到一定的范围 574.2.4　特征二值化 584.2.5　缺失数据处理 584.3　理解降维 594.3.1　在OpenCV 中实现主成分分析 614.3.2　实现独立成分分析 644.3.3　实现非负矩阵分解 654.4　类别变量表示 664.5　文本特征表示 684.6　图像表示 694.6.1　使用色彩空间 694.6.2　图像角点检测 714.6.3　使用尺度不变特征变换 724.6.4　使用加速健壮特征 744.7　总结 75第5章　使用决策树进行医疗诊断 765.1　理解决策树 765.1.1　构建第一个决策树 795.1.2　可视化训练得到的决策树 855.1.3　深入了解决策树的内部工作机制 875.1.4　特征重要性评分 885.1.5　理解决策规则 895.1.6　控制决策树的复杂度 905.2　使用决策树进行乳腺癌的诊断 905.2.1　载入数据集 915.2.2　构建决策树 925.3　使用决策树进行回归 965.4　总结 99第6章　使用支持向量机检测行人 1006.1　理解线性支持向量机 1006.1.1　学习最优决策边界 1016.1.2　实现我们的第一个支持向量机 1026.2　处理非线性决策边界 1076.2.1　理解核机制 1086.2.2　认识我们的核 1096.2.3　实现非线性支持向量机 1096.3　自然环境下的行人检测 1106.3.1　获取数据集 1116.3.2　初窥方向梯度直方图 1136.3.3　生成负样本 1146.3.4　实现支持向量机 1166.3.5　模型自举 1166.3.6　在更大的图像中检测行人 1186.3.7　进一步优化模型 1206.4　总结 121第7章　使用贝叶斯学习实现垃圾邮件过滤 1227.1　理解贝叶斯推断 1227.1.1　概率论的短暂之旅 1237.1.2　理解贝叶斯定理 1247.1.3　理解朴素贝叶斯分类器 1267.2　实现第一个贝叶斯分类器 1277.2.1　创建一个练习数据集 1277.2.2　使用一个正态贝叶斯分类器对数据分类 1287.2.3　使用一个朴素贝叶斯分类器对数据分类 1317.2.4　条件概率的可视化 1327.3　使用朴素贝叶斯分类器对邮件分类 1347.3.1　载入数据集 1347.3.2　使用Pandas构建数据矩阵 1367.3.3　数据预处理 1377.3.4　训练正态贝叶斯分类器 1387.3.5　使用完整的数据集进行训练 1397.3.6　使用n-gram提升结果 1397.3.7　使用TD-IDF提升结果 1407.4　总结 141第8章　使用非监督学习发现隐藏结构 1428.1　理解非监督学习 1428.2　理解k均值聚类 1438.3　理解期望最大化 1458.3.1　实现期望最大化解决方案 1468.3.2　了解期望最大化的局限 1488.4　使用k均值压缩色彩空间 1548.4.1　真彩色调色板的可视化 1548.4.2　使用k均值减少调色板 1578.5　使用k均值对手写数字分类 1598.5.1　载入数据集 1598.5.2　运行k均值 1598.6　把聚类组织成层次树 1618.6.1　理解层次聚类 1618.6.2　实现凝聚层次聚类 1628.7　总结 163第9章　使用深度学习对手写数字分类 1649.1　理解McCulloch-Pitts神经元 1649.2　理解感知器 1679.3　实现第一个感知器 1699.3.1　生成练习数据集 1709.3.2　使用数据拟合感知器 1719.3.3　评估感知器分类器 1719.3.4　把感知器应用到线性不可分的数据上 1739.4　理解多层感知器 1749.4.1　理解梯度下降 1759.4.2　使用反向传播训练多层感知器 1789.4.3　在OpenCV中实现多层感知器 1799.5　了解深度学习 1839.6　手写数字分类 1869.6.1　载入MNIST数据集 1879.6.2　MNIST数据集预处理 1889.6.3　使用OpenCV训练一个MLP 1899.6.4　使用Keras训练一个深度神经网络 1909.7　总结 192第10章　组合不同算法为一个整体 19310.1　理解集成方法 19310.1.1　理解平均集成 19510.1.2　理解提升集成 19710.1.3　理解堆叠集成 20010.2　组合决策树为随机森林 20010.2.1　理解决策树的不足 20010.2.2　实现第一个随机森林 20410.2.3　使用scikit-learn实现一个随机森林 20510.2.4　实现极端随机树 20610.3　使用随机森林进行人脸识别 20810.3.1　载入数据集 20810.3.2　预处理数据集 20910.3.3　训练和测试随机森林 21010.4　实现AdaBoost 21210.4.1　使用OpenCV实现AdaBoost 21210.4.2　使用scikit-learn实现AdaBoost 21310.5　组合不同模型为一个投票分类器 21410.5.1　理解不同的投票机制 21410.5.2　实现一个投票分类器 21510.6　总结 217第11章　通过超参数调优选择合适的模型 21811.1　评估一个模型 21811.1.1　评估模型错误的方法 21911.1.2　评估模型正确的方法 22011.1.3　选择最好的模型 22111.2　理解交叉验证 22311.2.1　使用OpenCV手动实现交叉验证 22511.2.2　使用scikit-learn进行k折交叉验证 22611.2.3　实现留一法交叉验证 22711.3　使用自举评估鲁棒性 22811.4　评估结果的重要性 23011.4.1　实现T检验 23011.4.2　实现配对卡方检验 23211.5　使用网格搜索进行超参数调优 23311.5.1　实现一个简单的网格搜索 23411.5.2　理解验证集的价值 23511.5.3　网格搜索结合交叉验证 23611.5.4　网格搜索结合嵌套交叉验证 23811.6　使用不同评估指标来对模型评分 23911.6.1　选择正确的分类指标 23911.6.2　选择正确的回归指标 24011.7　链接算法形成一个管道 24011.7.1　用 scikit-learn 实现管道 24111.7.2　在网格搜索中使用管道 24211.8　总结 243第12章　综合 24412.1　着手处理一个机器学习问题 24412.2　构建自己的估计器 24512.2.1　使用C  编写自己的基于OpenCV的分类器 24512.2.2　使用Python 编写自己的基于scikit-learn的分类器 24712.3　今后的方向 24912.4　总结 251 显示全部信息